'''
- AsyncIOScheduler ì‚¬ìš© (ë¹„ë™ê¸° ì§€ì›)
- ê° Job í•¨ìˆ˜ëŠ” ë§¤ ì‹¤í–‰ë§ˆë‹¤ ìƒˆë¡œìš´ DB ì„¸ì…˜ì„ ìƒì„±í•˜ì—¬ ë…ë¦½ì„± ë³´ì¥
- AIServiceëŠ” ë¸Œë¦¬í•‘ ìƒì„± ì‹œ ì±„íŒ… ë‚´ì—­ì´ í•„ìš” ì—†ìœ¼ë¯€ë¡œ chat_repo=Noneìœ¼ë¡œ ì´ˆê¸°í™”í•˜ì—¬ ë¦¬ì†ŒìŠ¤ë¥¼ ì ˆì•½
'''
import os
from datetime import datetime
from loguru import logger
from typing import Callable, Awaitable

from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
from sqlalchemy.ext.asyncio import AsyncSession

from app.db.session import AsyncSessionFactory
from app.repositories.schedule_repo import ScheduleRepository
from app.repositories.chat_repo import ChatRepository
from app.repositories.user_repo import UserRepository
from app.repositories.notification_repo import NotificationRepository
from app.repositories.job_history_repo import JobHistoryRepository

from app.services.cleanup_service import CleanupService
from app.services.briefing_service import BriefingService
from app.services.ai_service import AIService

scheduler = AsyncIOScheduler()

# ---------------------------------------------------------------------------
# 1. ë¡œê¹… ì„¤ì •
# ---------------------------------------------------------------------------
def setup_batch_logger():
    """ë°°ì¹˜ ì‘ì—… ì „ìš© íŒŒì¼ ë¡œê±° ì„¤ì •"""
    log_dir = "logs/batch"
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)
    
    # "batch" in record["extra"] -> "ì´ ë¡œê·¸ì˜ ê¼¬ë¦¬í‘œ ì¤‘ì— 'batch'ë¼ëŠ” ìŠ¤í‹°ì»¤ê°€ ë¶™ì–´ ìˆë‹ˆ?" ë¼ê³  ë¬»ìŠµë‹ˆë‹¤.
    #   * Yes: ì´ ë¡œê·¸ íŒŒì¼(logs/batch/...)ì— ì €ì¥í•©ë‹ˆë‹¤.
    #   * No: ì¼ë°˜ ë¡œê·¸ì´ë¯€ë¡œ ë¬´ì‹œí•˜ê³  ë‹¤ë¥¸ ê³³(ì½˜ì†” ë“±)ìœ¼ë¡œ ë³´ëƒ…ë‹ˆë‹¤.
    logger.add(
        os.path.join(log_dir, "{time:YYYY-MM-DD}_batch.log"),
        filter=lambda record: "batch" in record["extra"],
        format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}",
        rotation="00:00", # ë§¤ì¼ ìì • ë¡œí…Œì´ì…˜
        retention="30 days" # 30ì¼ ë³´ê´€
    )

# ---------------------------------------------------------------------------
# 2. ë°°ì¹˜ ì‹¤í–‰ ë˜í¼
# Callable[[AsyncSession], Awaitable[str]]: DB ì„¸ì…˜ì„ ë°›ì•„ì„œ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰ë˜ê³ , ëë‚˜ë©´ ë¬¸ìì—´ ê²°ê³¼ë¥¼ ëŒë ¤ì£¼ëŠ” í•¨ìˆ˜
# ---------------------------------------------------------------------------
async def run_job_with_logging(job_name: str, logic_func: Callable[[AsyncSession], Awaitable[str]]):
    """
    ë°°ì¹˜ ì‘ì—… ì‹¤í–‰ ê³µí†µ ë˜í¼
    - DB ì„¸ì…˜ ê´€ë¦¬
    - JobHistory ê¸°ë¡ (SUCCESS/FAILED)
    - íŒŒì¼ ë¡œê¹…
    """
    # ë°°ì¹˜ ì „ìš© ë¡œê±° ë°”ì¸ë”©
    # ì½”ë“œì—ì„œ logger.bind(batch=True).info(...)ë¼ê³  ë¡œê·¸ë¥¼ ì°ìœ¼ë©´, ê·¸ ë¡œê·¸ ë©”ì‹œì§€ì—ëŠ” ë³´ì´ì§€ ì•ŠëŠ” ê¼¬ë¦¬í‘œ(extra ì •ë³´)ë¡œ {'batch': True}ê°€ ë¶™ìŠµë‹ˆë‹¤.
    # ==> ë§ˆì¹˜ íƒë°° ìƒìì— "ì·¨ê¸‰ì£¼ì˜" ìŠ¤í‹°ì»¤ë¥¼ ë¶™ì´ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤.
    batch_logger = logger.bind(batch=True)
    batch_logger.info(f"[{job_name}] STARTING...")
    
    async with AsyncSessionFactory() as session:
        repo = JobHistoryRepository(session)
        status = "FAILED",
        details = ""
        
        try:
            # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì‹¤í–‰
            result_msg = await logic_func(session)
            status = "SUCCESS"
            details = result_msg
            batch_logger.info(f"[{job_name}] COMPLETED. {details}")
        
        except Exception as e:
            status = "FAILED"
            details = str(e)
            batch_logger.error(f"[{job_name}] FAILED. Error: {details}")
            batch_logger.exception(e) # ì—ëŸ¬ ìŠ¤íƒíŠ¸ë ˆì´ìŠ¤ ë¡œê·¸
            
        finally:
            try:
                await repo.create_log(job_name, status, details)
                await session.commit()
            except Exception as db_err:
                batch_logger.error(f"[{job_name}] Failed to save job history: {db_err}")
            
            
# ---------------------------------------------------------------------------
# 3. ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
# ---------------------------------------------------------------------------
async def _cleanup_logic(session: AsyncSession) -> str:
    """ë°ì´í„° í´ë¦°ì—… ë°°ì¹˜ (ë§¤ì¼ ìƒˆë²½ 3ì‹œ)"""
    cleanup_service = CleanupService(
        schedule_repo = ScheduleRepository(session),
        chat_repo = ChatRepository(session)
    )
    
    # ë§Œë£Œëœ ì¼ì • ì‚­ì œ
    deleted_schedules = await cleanup_service.delete_expired_schedules()
    
    # ë§Œë£Œëœ ì±„íŒ… ì‚­ì œ
    deleted_chats = await cleanup_service.delete_expired_chats()
    
    return f"Schedules: {deleted_schedules}, Chats: {deleted_chats}"

async def _briefing_logic(session: AsyncSession) -> str:
    """AI ëª¨ë‹ ë¸Œë¦¬í•‘ ìƒì„± (ë§¤ì¼ ì•„ì¹¨ 7ì‹œ)"""
    user_repo = UserRepository(session)
    briefing_service = BriefingService(
        schedule_repo = ScheduleRepository(session),
        notification_repo = NotificationRepository(session),
        ai_service = AIService()
    )
    
    # ëª¨ë“  ì‚¬ìš©ì ì¡°íšŒ
    users = await user_repo.get_all_users()
    success_count = 0
    fail_count = 0
    
    for user in users:
        try:
            await briefing_service.create_daily_briefing(user.id)
            success_count += 1
        except Exception:
            fail_count += 1
    return f"Total Users: {len(users)}, Success: {success_count}, Failed: {fail_count}"

# ---------------------------------------------------------------------------
# 4. Job ì§„ì…ì  (Entry Point)
# ---------------------------------------------------------------------------
async def run_cleanup_job():
    await run_job_with_logging("daily_cleanup", _cleanup_logic)
    
async def run_morning_briefing_job():
    await run_job_with_logging("morning_briefing", _briefing_logic)


# ---------------------------------------------------------------------------
# 5. Startup Check (Smart Recovery)
#   * ì •ì±… A (ëª¨ë‹ ë¸Œë¦¬í•‘):
#       * ì‹œê°„: 07:00 ~ 12:00 ì‚¬ì´ ê¸°ë™
#       * ì¡°ê±´: ì˜¤ëŠ˜ ì„±ê³µí•œ morning_briefing ë¡œê·¸ê°€ ì—†ìŒ
#       * í–‰ë™: run_morning_briefing_job() ì¦‰ì‹œ ì‹¤í–‰
#
#   * ì •ì±… B (ë°ì´í„° í´ë¦°ì—…):
#       * ì‹œê°„: 03:00 ~ 07:00 ì‚¬ì´ ê¸°ë™ (ìƒˆë²½ ì ê²€ í›„ ì¬ê¸°ë™ ì‹œë‚˜ë¦¬ì˜¤)
#       * ì¡°ê±´: ì˜¤ëŠ˜ ì„±ê³µí•œ daily_cleanup ë¡œê·¸ê°€ ì—†ìŒ
#       * í–‰ë™: run_cleanup_job() ì¦‰ì‹œ ì‹¤í–‰
# ---------------------------------------------------------------------------
async def check_and_run_missed_jobs():
    """
    ì„œë²„ ì‹œì‘ ì‹œ ì‹¤í–‰ë˜ì§€ ì•Šì€ ë°°ì¹˜ ì‘ì—…ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ë³µêµ¬(Recovery) ìˆ˜í–‰
    """
    now = datetime.now()
    logger.info(f"Checking for missed batch jobs at {now}...")
    
    async with AsyncSessionFactory() as session:
        repo = JobHistoryRepository(session)
        
        # 1. ëª¨ë‹ ë¸Œë¦¬í•‘ ë³µêµ¬(07:00 ~ 12:00)
        if 0 <= now.hour < 24:
            if not await repo.exists_successful_job_today("morning_briefing"):
                logger.warning("Recovery: Missed 'morning_briefing' detected. Executing now...")
                await run_morning_briefing_job()
            else:
                logger.info("Recovery: 'morning_briefing' already executed today")
                
        # 2. ë°ì´í„° í´ë¦°ì—… ë³µêµ¬ (03:00 ~ 07:00)
        if 0 <= now.hour < 24:
            if not await repo.exists_successful_job_today("daily_cleanup"):
                logger.warning("Recovery: Missed 'daily_cleanup' detected. Executing now...")
                await run_cleanup_job()
            else:
                logger.info("Recovery: 'daily_cleanup' already executed today.")

# ---------------------------------------------------------------------------
# 6. ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
# ---------------------------------------------------------------------------
async def start_scheduler():
    """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ë° Job ë“±ë¡ + ë³µêµ¬ ë¡œì§ ìˆ˜í–‰"""
    setup_batch_logger()
    
    if not scheduler.running:
        # Job 1: ë°ì´í„° í´ë¦°ì—… (ë§¤ì¼ 03:00)
        scheduler.add_job(
            run_cleanup_job,
            CronTrigger(hour=3, minute=0),
            id="daily_cleanup",
            replace_existing=True
        )
        # Job 2: ëª¨ë‹ ë¸Œë¦¬í•‘ (ë§¤ì¼ 07:00)
        scheduler.add_job(
            run_morning_briefing_job,
            CronTrigger(hour=7, minute=0),
            id="morning_briefing",
            replace_existing=True
        )
        scheduler.start()
        logger.info("Scheduler started...")
        
        await check_and_run_missed_jobs()
        
def shutdown_scheduler():
    """ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œ"""
    if scheduler.running:
        scheduler.shutdown()
        logger.info("Scheduler shutdown.")

'''
  ğŸ›ï¸ ì½”ë“œì˜ í•µì‹¬ êµ¬ì¡° (Architecture Overview)

  ì´ ì½”ë“œëŠ” "ì±…ì„ì˜ ë¶„ë¦¬(Separation of Concerns)" ì›ì¹™ì„ ë”°ë¦…ë‹ˆë‹¤.
  í•˜ë‚˜ì˜ ê±°ëŒ€í•œ run_job í•¨ìˆ˜ê°€ ëª¨ë“  ì¼(DBì—°ê²°, ë¡œì§ì‹¤í–‰, ë¡œê¹…, ì˜ˆì™¸ì²˜ë¦¬)ì„ ë‹¤ í•˜ëŠ” ëŒ€ì‹ , ì—­í• ì„ ëª…í™•íˆ ìª¼ê°°ìŠµë‹ˆë‹¤.

   1. Wrapper (ê»ë°ê¸°/ê´€ë¦¬ì): run_job_with_logging
       * "ë‚˜ëŠ” ì¼(Logic)ì„ ì‹œí‚¤ê³ , ê²°ê³¼ë§Œ ê¸°ë¡í•´. ë¬´ìŠ¨ ì¼ì¸ì§€ëŠ” ê´€ì‹¬ ì—†ì–´."
       * DB ì„¸ì…˜ ìƒì„±, ì„±ê³µ/ì‹¤íŒ¨ ì—¬ë¶€ íŒë‹¨, ë¡œê·¸ íŒŒì¼ ê¸°ë¡, JobHistory ì €ì¥ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.

   2. Logic (ì•Œë§¹ì´/ì‘ì—…ì): _cleanup_logic, _briefing_logic
       * "ë‚˜ëŠ” ì‹œí‚¤ëŠ” ì¼ë§Œ í•´. ê¸°ë¡ì´ë‚˜ DB ì—°ê²°ì€ ëª°ë¼."
       * ì‹¤ì œ ì„œë¹„ìŠ¤(CleanupService ë“±)ë¥¼ í˜¸ì¶œí•˜ê³ , ê²°ê³¼ ë©”ì‹œì§€(ë¬¸ìì—´)ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.

   3. Entry Point (í˜¸ì¶œ ë²„íŠ¼): run_cleanup_job
       * ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ëˆ„ë¥´ëŠ” ë²„íŠ¼ì…ë‹ˆë‹¤. ë‹¨ìˆœíˆ "ê´€ë¦¬ìì•¼(Wrapper), ì²­ì†Œë¶€(Logic) ì¢€ ì‹œì¼œì¤˜"ë¼ê³  ì—°ê²°ë§Œ í•´ì¤ë‹ˆë‹¤.

  ---

  ğŸŒŠ ì½”ë“œ ì‹¤í–‰ íë¦„ (Execution Flow)

  ë§¤ì¼ ìƒˆë²½ 3ì‹œ, daily_cleanup ì‘ì—…ì´ ì‹¤í–‰ë  ë•Œì˜ ì‹œë‚˜ë¦¬ì˜¤ì…ë‹ˆë‹¤.

  1ë‹¨ê³„: ìŠ¤ì¼€ì¤„ëŸ¬ íŠ¸ë¦¬ê±°
   * APSchedulerê°€ 03:00ì— run_cleanup_job() í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.

  2ë‹¨ê³„: ë˜í¼ í˜¸ì¶œ (ìœ„ì„)
   * run_cleanup_jobì€ ì¦‰ì‹œ run_job_with_logging("daily_cleanup", _cleanup_logic)ì„ í˜¸ì¶œí•©ë‹ˆë‹¤.
       * "ì‘ì—… ì´ë¦„ì€ 'daily_cleanup'ì´ê³ , í•  ì¼ì€ `_cleanup_logic` í•¨ìˆ˜ì— ìˆì–´." ë¼ê³  ì „ë‹¬í•©ë‹ˆë‹¤.

  3ë‹¨ê³„: ê´€ë¦¬ì(Wrapper)ì˜ ì¤€ë¹„
   * run_job_with_loggingì´ ì‹œì‘ë©ë‹ˆë‹¤.
   * íŒŒì¼ ë¡œê·¸: logs/batch/2025-12-16_batch.log íŒŒì¼ì— [daily_cleanup] STARTING...ì´ë¼ê³  ì ìŠµë‹ˆë‹¤.
   * DB ì„¸ì…˜: AsyncSessionFactory()ë¡œ ìƒˆ DB ì„¸ì…˜ì„ ì—½ë‹ˆë‹¤.

  4ë‹¨ê³„: ì•Œë§¹ì´(Logic) ì‹¤í–‰
   * await logic_func(session) ì½”ë“œê°€ ì‹¤í–‰ë˜ë©´ì„œ, ì‹¤ì œë¡œ _cleanup_logic(session) í•¨ìˆ˜ê°€ ëŒì•„ê°‘ë‹ˆë‹¤.
       * CleanupServiceê°€ ìƒì„±ë˜ê³ , delete_expired_schedules() ë“±ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
       * ì‘ì—…ì´ ëë‚˜ë©´ ê²°ê³¼ ë¬¸ìì—´("Schedules: 5, Chats: 0")ì„ ë¦¬í„´í•©ë‹ˆë‹¤.

  5ë‹¨ê³„: ê²°ê³¼ ì²˜ë¦¬ (ì„±ê³µ ì‹œ)
   * ë˜í¼ëŠ” ë¦¬í„´ë°›ì€ ë¬¸ìì—´ì„ details ë³€ìˆ˜ì— ë‹´ìŠµë‹ˆë‹¤.
   * statusë¥¼ "SUCCESS"ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
   * íŒŒì¼ ë¡œê·¸: [daily_cleanup] COMPLETED. Schedules: 5...ë¼ê³  ì ìŠµë‹ˆë‹¤.

  6ë‹¨ê³„: ì´ë ¥ ì €ì¥ (Finally)
   * ì„±ê³µí•˜ë“  ì‹¤íŒ¨í•˜ë“  finally ë¸”ë¡ìœ¼ë¡œ ê°‘ë‹ˆë‹¤.
   * JobHistoryRepository.create_log("daily_cleanup", "SUCCESS", "Schedules: 5...")ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
   * DB Commit: job_histories í…Œì´ë¸”ì— í•œ ì¤„ì´ ì¶”ê°€ë©ë‹ˆë‹¤.

  ---

  ğŸ’¡ ì™œ ì´ë ‡ê²Œ ë³µì¡í•˜ê²Œ ë‚˜ëˆ„ë‚˜ìš”?

  ì²˜ìŒì—” ë³µì¡í•´ ë³´ì¼ ìˆ˜ ìˆì§€ë§Œ, ì´ë ‡ê²Œ í•˜ë©´ ì—„ì²­ë‚œ ì¥ì ì´ ìƒê¹ë‹ˆë‹¤.

   1. ìƒˆ ì‘ì—… ì¶”ê°€ê°€ ë§¤ìš° ì‰½ìŠµë‹ˆë‹¤.
       * ë§Œì•½ "ë§¤ì£¼ ì›”ìš”ì¼ ì£¼ê°„ ë¦¬í¬íŠ¸" ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ê³  ì‹¶ë‹¤ë©´?
       * _report_logic í•¨ìˆ˜ í•˜ë‚˜ë§Œ ì§œë©´ ë©ë‹ˆë‹¤. ë¡œê·¸ ë‚¨ê¸°ê³ , DB ì €ì¥í•˜ê³ , ì˜ˆì™¸ ì²˜ë¦¬í•˜ëŠ” ì½”ë“œëŠ” run_job_with_loggingì´ ì•Œì•„ì„œ ë‹¤ í•´ì£¼ë‹ˆê¹Œìš”. (ë³µì‚¬-ë¶™ì—¬ë„£ê¸° í•  í•„ìš” ì—†ìŒ)

   2. ëª¨ë“  ë¡œê·¸ í˜•ì‹ì´ í†µì¼ë©ë‹ˆë‹¤.
       * ì–´ë–¤ ì‘ì—…ì´ë“  ë¡œê·¸ í¬ë§·ì´ ë˜‘ê°™ì•„ì„œ(STARTING -> COMPLETED/FAILED), ë‚˜ì¤‘ì— ë¡œê·¸ ë¶„ì„ê¸°ë‚˜ ëª¨ë‹ˆí„°ë§ íˆ´ì„ ë¶™ì´ê¸° í¸í•©ë‹ˆë‹¤.

   3. ì—ëŸ¬ ê´€ë¦¬ê°€ ì•ˆì „í•©ë‹ˆë‹¤.
       * ê°œë°œìê°€ ì‹¤ìˆ˜ë¡œ try-exceptë¥¼ ë¹¼ë¨¹ì–´ë„, ë˜í¼ í•¨ìˆ˜ê°€ ì¡ì•„ì£¼ê¸° ë•Œë¬¸ì— ì„œë²„ê°€ ì£½ì§€ ì•Šê³  "FAILED"ë¡œ ê¸°ë¡ë©ë‹ˆë‹¤.

"í…œí”Œë¦¿ ë©”ì„œë“œ íŒ¨í„´(Template Method Pattern)"
'''